# üö¢ Titanic ML Pipeline - End-to-End Machine Learning Project

[![Python 3.8+](https://img.shields.io/badge/python-3.8%2B-blue)](https://www.python.org/)
[![GitHub Actions CI/CD](https://img.shields.io/badge/CI/CD-GitHub_Actions-2088FF?logo=github-actions&logoColor=white)](https://github.com/features/actions)
[![Scikit-learn](https://img.shields.io/badge/ML-Scikit--learn-F7931E?logo=scikit-learn&logoColor=white)](https://scikit-learn.org/)
[![Flask API](https://img.shields.io/badge/API-Flask-000000?logo=flask&logoColor=white)](https://flask.palletsprojects.com/)
[![Pytest](https://img.shields.io/badge/Testing-Pytest-0A9EDC?logo=python&logoColor=white)](https://docs.pytest.org/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

## üìã Tabla de Contenidos
- [üöÄ Inicio R√°pido](#-inicio-r√°pido)
- [üèÉ‚Äç‚ôÇÔ∏è Gu√≠a de Ejecuci√≥n Paso a Paso](#-gu√≠a-de-ejecuci√≥n-paso-a-paso)
- [üê≥ Ejecuci√≥n con Docker](#-ejecuci√≥n-con-docker)
- [üìä Verificaci√≥n y Monitoreo](#-verificaci√≥n-y-monitoreo)
- [üîß Operaciones Avanzadas](#-operaciones-avanzadas)
- [üÜò Soluci√≥n de Problemas](#-soluci√≥n-de-problemas)
- [üìÅ Estructura del Proyecto](#-estructura-del-proyecto)

## üöÄ Inicio R√°pido

### Prerrequisitos
```bash
# Solo necesitas:
python --version  # Python 3.8+
git --version     # Git

# Clonar el repositorio
git clone https://github.com/D4n0nin0/kaggle-titanic-ml-pipeline.git
cd kaggle-titanic-ml-pipeline

# Crear entorno virtual (Linux/Mac)
python -m venv venv
source venv/bin/activate

# Windows:
# python -m venv venv
# venv\Scripts\activate

# Instalar dependencias
pip install -r requirements.txt


# Paso 1 VERIFICAR INSTALACION

# Verificar versi√≥n de Python
python --version

# Verificar que todas las dependencias se instalaron correctamente
python -c "import sklearn; import flask; import pandas as pd; print('‚úÖ Todas las dependencias instaladas correctamente!')"

# Paso 2 VERIFICAR LA ESTRUCTURA DEL PROYECTO

# Ver organizaci√≥n completa del proyecto
ls -la

# Ver contenido del directorio data/
ls data/

# Ver c√≥digo fuente
ls src/

# Ver archivos de tests
ls tests/


# Paso 3 PREPROCESAMIENTO DE DATOS

# Ejecutar preprocesamiento de datos
python -c "
from src.data_preprocessing import preprocess_data
preprocess_data('data/train.csv', 'data/processed_train.csv')
print('‚úÖ Preprocesamiento de datos completado exitosamente!')
print('üìä Datos procesados guardados en: data/processed_train.csv')
"


# Paso 4 ENTRENAMIENTO DEL MODELO DE ML

# Entrenar el modelo (crear√° archivos en models/)
python src/train.py

# Verificar que se crearon los archivos del modelo
ls models/
# Deber√≠as ver: random_forest_titanic.pkl y model_metrics.json


# Paso 5  EJECUTAR TESTS 

# Ejecutar todos los tests con output verbose
python -m pytest tests/ -v

# Ejecutar tests con reporte de cobertura
python -m pytest --cov=src tests/ --cov-report=term-missing

# Ejecutar tests espec√≠ficos
python -m pytest tests/test_api.py -v

# Paso 6 INICIAR EL API DE PREDICCIONES

# Iniciar Flask API (ejecutar√° en http://localhost:5000)
python src/api.py

# Mant√©n esta terminal abierta - el API seguir√° ejecut√°ndose
# Abre una nueva terminal para los siguientes pasos

# Paso 7 PROBAR ENDPOINT DE HEALTH DEL API

# Probar endpoint de health (en nueva terminal)
curl http://localhost:5000/health

# Respuesta esperada:
# {"status": "healthy", "model_loaded": true, "version": "1.0"}

#PASO 8 PROBAR ENDPOINT DE PREDICCIONES  CON DIFERENTES ESCENARIOS

# Caso de prueba 1: Mujer primera clase (alta probabilidad de supervivencia)
curl -X POST http://localhost:5000/predict \
  -H "Content-Type: application/json" \
  -d '{
    "Pclass": 1,
    "Sex": "female", 
    "Age": 25,
    "SibSp": 0,
    "Parch": 0,
    "Fare": 50,
    "Embarked": "C"
  }'

# Caso de prueba 2: Hombre tercera clase (baja probabilidad de supervivencia)
curl -X POST http://localhost:5000/predict \
  -H "Content-Type: application/json" \
  -d '{
    "Pclass": 3,
    "Sex": "male", 
    "Age": 30,
    "SibSp": 0,
    "Parch": 0,
    "Fare": 7.5,
    "Embarked": "S"
  }'

# Caso de prueba 3: Grupo familiar
curl -X POST http://localhost:5000/predict \
  -H "Content-Type: application/json" \
  -d '{
    "Pclass": 2,
    "Sex": "female", 
    "Age": 28,
    "SibSp": 1,
    "Parch": 2,
    "Fare": 25,
    "Embarked": "Q"
  }'


# Paso 9 EXPLORAR JUPYTER NOTEBOOKS PARA ANALISIS

# Instalar Jupyter si no est√° instalado
pip install jupyter

# Iniciar servidor de Jupyter notebook
jupyter notebook

# En la interfaz web, abrir y ejecutar:
# 1. notebooks/01_eda.ipynb (An√°lisis Exploratorio de Datos)
# 2. notebooks/02_data_preprocessing.ipynb 
# 3. notebooks/03_model_training.ipynb

# Paso 10 EJECUTAR PIPELINE COMPLETO

# Ejecutar todo el pipeline de principio a fin
python src/train.py && python -m pytest tests/ -v && python src/api.py

